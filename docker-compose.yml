# Purpose: Local dev docker-compose for the F1 lakehouse (MinIO + Spark cluster).
# Tip: Copy secrets into a .env file at repo root (MINIO_ROOT_USER/MINIO_ROOT_PASSWORD, S3A_*).
# Notes:
# - Run with: docker compose up --build
# - Access MinIO UI: http://localhost:9001  Spark UI: http://localhost:8080 (master), http://localhost:8081 (worker)
# - Persist MinIO data via the named volume `minio`

services:
  # ----------------------------
  # 1) MinIO = "S3-compatible" object storage
  # ----------------------------
  # Local replacement for AWS S3 used by Spark via s3a://
  minio:
    image: minio/minio:latest
    # Run MinIO server and expose console on port 9001
    command: server /data --console-address ":9001"

    # Load admin credentials from .env
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}

    # Persist bucket data on the host
    volumes:
      - minio:/data

    # Host:container port mappings
    ports:
      - "9000:9000"   # S3 API endpoint
      - "9001:9001"   # Web console

  # ----------------------------
  # 2) createbuckets = one-time setup container
  # ----------------------------
  # Uses `mc` (MinIO client) to create the bucket defined in LAKEHOUSE_BUCKET.
  # This container exits after creating the bucket; it is safe to re-run.
  createbuckets:
    image: minio/mc:latest

    # Ensure MinIO is available before running the script
    depends_on:
      - minio

    # The script waits until MinIO is ready, configures an alias, and creates the bucket.
    # `|| true` makes the step idempotent if bucket already exists.
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO to be ready...';
      until mc alias set local ${MINIO_ENDPOINT} ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do
        echo 'MinIO not ready yet - sleeping 2s';
        sleep 2;
      done;
      echo 'MinIO is ready. Creating bucket...';
      mc mb -p local/${LAKEHOUSE_BUCKET} || true;
      echo 'Done.';
      "

  # ----------------------------
  # 3) Spark Master
  # ----------------------------
  # Single-node master used for local experiments. Image is built from Dockerfile.spark.
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: ${SPARK_IMAGE}
    container_name: spark-master
    environment:
      # Provide S3A credentials + paths to Delta locations via environment (from .env).
      # These are injected into the Spark container so jobs can read/write to MinIO.
      S3A_ACCESS_KEY: ${S3A_ACCESS_KEY}
      S3A_SECRET_KEY: ${S3A_SECRET_KEY}
      S3A_ENDPOINT: ${S3A_ENDPOINT}
      AWS_ACCESS_KEY_ID: ${S3A_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${S3A_SECRET_KEY}
      BRONZE_DELTA_PATH: ${BRONZE_DELTA_PATH}
      SILVER_DELTA_PATH: ${SILVER_DELTA_PATH}
      DQ_DELTA_PATH: ${DQ_DELTA_PATH}
    ports:
      - "7077:7077"   # Spark master port
      - "8080:8080"   # Spark master UI
    volumes:
      - ./spark/jobs:/opt/spark/jobs     # place job scripts here
      - ./spark/conf:/opt/spark/conf     # custom Spark configuration (spark-defaults.conf)
      - ./spark/lib:/opt/spark/app_lib   # additional jars/libraries for Spark
    command: >
      /bin/bash -lc "
      /opt/spark/sbin/start-master.sh --host spark-master;
      tail -f /opt/spark/logs/*"

  # ----------------------------
  # Spark Worker
  # ----------------------------
  # Worker node that registers to the master. Keep it lightweight for local testing.
  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    image: ${SPARK_IMAGE}
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      # Mirror S3A and path env vars so worker tasks have same access
      S3A_ACCESS_KEY: ${S3A_ACCESS_KEY}
      S3A_SECRET_KEY: ${S3A_SECRET_KEY}
      S3A_ENDPOINT: ${S3A_ENDPOINT}
      AWS_ACCESS_KEY_ID: ${S3A_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${S3A_SECRET_KEY}
      BRONZE_DELTA_PATH: ${BRONZE_DELTA_PATH}
      SILVER_DELTA_PATH: ${SILVER_DELTA_PATH}
      DQ_DELTA_PATH: ${DQ_DELTA_PATH}
    ports:
      - "8081:8081"   # Spark worker web UI
    volumes:
      - ./spark/jobs:/opt/spark/jobs
      - ./spark/conf:/opt/spark/conf
      - ./spark/lib:/opt/spark/app_lib
    command: >
      /bin/bash -lc "
      /opt/spark/sbin/start-worker.sh spark://spark-master:7077;
      tail -f /opt/spark/logs/*"

# ----------------------------
# Named volumes
# ----------------------------
# Persisted Docker volume for MinIO data. Add more volumes if you want to persist Spark state.
volumes:
  minio:
